{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import helperFunc\r\n",
    "import glob\r\n",
    "import os\r\n",
    "import re\r\n",
    "import random\r\n",
    "import math\r\n",
    "import numpy as np\r\n",
    "from PIL import ImageEnhance,ImageOps\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import cv2\r\n",
    "from multiprocessing import Pool\r\n",
    "\r\n",
    "\r\n",
    "from keras.optimizers import SGD,Adam\r\n",
    "from keras.layers.core import Lambda\r\n",
    "import keras.backend as K\r\n",
    "from keras import optimizers\r\n",
    "from keras.callbacks import ModelCheckpoint,Callback\r\n",
    "from keras.activations import relu\r\n",
    "from keras.layers.merge import concatenate\r\n",
    "from keras import regularizers\r\n",
    "from keras.layers import Input, GlobalAveragePooling2D ,Dense, Concatenate,Conv2DTranspose,Conv2D,Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\r\n",
    "from keras.layers.normalization import BatchNormalization\r\n",
    "from keras.models import Model\r\n",
    "from keras.applications.resnet50 import ResNet50\r\n",
    "from keras.applications import densenet\r\n",
    "\r\n",
    "\r\n",
    "# Putting this in for some errors that occur on my setup\r\n",
    "import tensorflow.compat.v1 as tf\r\n",
    "tf.disable_v2_behavior()\r\n",
    "from keras.backend.tensorflow_backend import set_session\r\n",
    "config = tf.ConfigProto()\r\n",
    "config.gpu_options.allow_growth = True\r\n",
    "set_session(tf.Session(config=config))\r\n",
    "\r\n",
    "K.set_image_data_format('channels_first')\r\n",
    "\r\n",
    "# np.random.seed(1337) # for reproducibility\r\n",
    "\r\n",
    "#Number of classes\r\n",
    "classes = 293\r\n",
    "\r\n",
    "#Length of feature vector\r\n",
    "FEATURES = 1024\r\n",
    "\r\n",
    "#Image dimensions, square images only, can change to non-square\r\n",
    "imgDimension = 256\r\n",
    "\r\n",
    "#Dataset location\r\n",
    "datasetLoc = 'training_dataset_folder/*'\r\n",
    "\r\n",
    "#Batch_size for training, can fit 12 in a GTX 1070 with ResNet 50\r\n",
    "BATCH_SIZE = 12\r\n",
    "\r\n",
    "#Num of images per class, for batch hard training\r\n",
    "im_per_class = 4 \r\n",
    "\r\n",
    "#Sorting for file reads\r\n",
    "numbers = re.compile(r'(\\d+)')\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n",
      "E:\\Dev\\Anaconda3\\envs\\iris\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\Dev\\Anaconda3\\envs\\iris\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\Dev\\Anaconda3\\envs\\iris\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\Dev\\Anaconda3\\envs\\iris\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\Dev\\Anaconda3\\envs\\iris\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\Dev\\Anaconda3\\envs\\iris\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From E:\\Dev\\Anaconda3\\envs\\iris\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "E:\\Dev\\Anaconda3\\envs\\iris\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\Dev\\Anaconda3\\envs\\iris\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\Dev\\Anaconda3\\envs\\iris\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\Dev\\Anaconda3\\envs\\iris\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\Dev\\Anaconda3\\envs\\iris\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\Dev\\Anaconda3\\envs\\iris\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def numericalSort(value):\r\n",
    "    parts = numbers.split(value)\r\n",
    "    parts[1::2] = map(int, parts[1::2])\r\n",
    "    return parts\r\n",
    "\r\n",
    "def rotate_image(image, angle):\r\n",
    "    \"\"\"\r\n",
    "    Rotates an OpenCV 2 / NumPy image about it's centre by the given angle\r\n",
    "    (in degrees). The returned image will be large enough to hold the entire\r\n",
    "    new image, with a black background, taken from stackoverflow (https://stackoverflow.com/questions/9041681/opencv-python-rotate-image-by-x-degrees-around-specific-point)\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    # Get the image size\r\n",
    "    # No that's not an error - NumPy stores image matricies backwards\r\n",
    "    image_size = (image.shape[1], image.shape[0])\r\n",
    "    image_center = tuple(np.array(image_size) / 2)\r\n",
    "\r\n",
    "    # Convert the OpenCV 3x2 rotation matrix to 3x3\r\n",
    "    rot_mat = np.vstack(\r\n",
    "        [cv2.getRotationMatrix2D(image_center, angle, 1.0), [0, 0, 1]]\r\n",
    "    )\r\n",
    "\r\n",
    "    rot_mat_notranslate = np.matrix(rot_mat[0:2, 0:2])\r\n",
    "\r\n",
    "    # Shorthand for below calcs\r\n",
    "    image_w2 = image_size[0] * 0.5\r\n",
    "    image_h2 = image_size[1] * 0.5\r\n",
    "\r\n",
    "    # Obtain the rotated coordinates of the image corners\r\n",
    "    rotated_coords = [\r\n",
    "        (np.array([-image_w2,  image_h2]) * rot_mat_notranslate).A[0],\r\n",
    "        (np.array([ image_w2,  image_h2]) * rot_mat_notranslate).A[0],\r\n",
    "        (np.array([-image_w2, -image_h2]) * rot_mat_notranslate).A[0],\r\n",
    "        (np.array([ image_w2, -image_h2]) * rot_mat_notranslate).A[0]\r\n",
    "    ]\r\n",
    "\r\n",
    "    # Find the size of the new image\r\n",
    "    x_coords = [pt[0] for pt in rotated_coords]\r\n",
    "    x_pos = [x for x in x_coords if x > 0]\r\n",
    "    x_neg = [x for x in x_coords if x < 0]\r\n",
    "\r\n",
    "    y_coords = [pt[1] for pt in rotated_coords]\r\n",
    "    y_pos = [y for y in y_coords if y > 0]\r\n",
    "    y_neg = [y for y in y_coords if y < 0]\r\n",
    "\r\n",
    "    right_bound = max(x_pos)\r\n",
    "    left_bound = min(x_neg)\r\n",
    "    top_bound = max(y_pos)\r\n",
    "    bot_bound = min(y_neg)\r\n",
    "\r\n",
    "    new_w = int(abs(right_bound - left_bound))\r\n",
    "    new_h = int(abs(top_bound - bot_bound))\r\n",
    "\r\n",
    "    trans_mat = np.matrix([\r\n",
    "        [1, 0, int(new_w * 0.5 - image_w2)],\r\n",
    "        [0, 1, int(new_h * 0.5 - image_h2)],\r\n",
    "        [0, 0, 1]\r\n",
    "    ])\r\n",
    "\r\n",
    "    # Compute the tranform for the combined rotation and translation\r\n",
    "    affine_mat = (np.matrix(trans_mat) * np.matrix(rot_mat))[0:2, :]\r\n",
    "\r\n",
    "    # Apply the transform\r\n",
    "    result = cv2.warpAffine(\r\n",
    "        image,\r\n",
    "        affine_mat,\r\n",
    "        (new_w, new_h),\r\n",
    "        flags=cv2.INTER_LINEAR\r\n",
    "    )\r\n",
    "\r\n",
    "    return result\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "'''\r\n",
    "    Augment function, needs an image and an augment type integer.\r\n",
    "'''\r\n",
    "def augment(im,augType):\r\n",
    "        if(augType == 0):\r\n",
    "            kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\r\n",
    "            im = cv2.filter2D(im, -1, kernel)\r\n",
    "        if(augType == 1):\r\n",
    "            im = rotate_image(im,30)\r\n",
    "            im =cv2.resize(im,(imgDimension,imgDimension))\r\n",
    "        if(augType == 2):\r\n",
    "            im = rotate_image(im,120)\r\n",
    "            im =cv2.resize(im,(imgDimension,imgDimension))\r\n",
    "        if(augType == 3):\r\n",
    "            im = rotate_image(im,320)\r\n",
    "            im =cv2.resize(im,(imgDimension,imgDimension))\r\n",
    "        if(augType == 4):\r\n",
    "            im = rotate_image(im,230)\r\n",
    "            im =cv2.resize(im,(imgDimension,imgDimension))\r\n",
    "        if(augType == 5):\r\n",
    "            im = np.flip(im,0)\r\n",
    "        if(augType == 6):\r\n",
    "            im = np.flip(im,1)\r\n",
    "        if(augType == 7):\r\n",
    "            im[0:70] = 0\r\n",
    "        if(augType == 8):\r\n",
    "            cl1 = clahe.apply(im[:,:,0])\r\n",
    "            cl1[cl1<10] = 0\r\n",
    "            im[:,:,0] = cl1\r\n",
    "            im[:,:,1] = cl1\r\n",
    "            im[:,:,2] = cl1\r\n",
    "        if (augType == 9):\r\n",
    "            im = cv2.blur(im, (3,3))\r\n",
    "        return im\r\n",
    "\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "    Keras generator for loading images in a batch hard fashion. Multithreaded by default in keras.\r\n",
    "    Modeled for a Tensorflow backend. Takes a static string to the dataset location.\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "folderList = sorted(glob.glob(datasetLoc),key=numericalSort)\r\n",
    "\r\n",
    "def customGenerator():\r\n",
    "    CLASSES = classes\r\n",
    "    K = im_per_class\r\n",
    "    batchSize = BATCH_SIZE\r\n",
    "    #Static paths for now\r\n",
    "\r\n",
    "    yConcat = np.zeros(shape = (batchSize,1+FEATURES),dtype = np.int32)\r\n",
    "    \r\n",
    "    while True:\r\n",
    "        y2 = np.zeros(shape = (1+FEATURES),dtype = np.int32)\r\n",
    "        xI = np.zeros(shape = (batchSize,3,imgDimension,imgDimension))\r\n",
    "        numFm = random.sample(range(CLASSES), batchSize//K)\r\n",
    "        for x in range(batchSize//K):\r\n",
    "            imList = glob.glob(folderList[numFm[x]] + \"/*\")\r\n",
    "            numIm = random.sample(range(len(imList)), K)\r\n",
    "            #Augmentation, comment out if not needed\r\n",
    "            augType = random.sample(range(9), 1)\r\n",
    "            for i in range(len(numIm)):\r\n",
    "                im = cv2.imread(imList[numIm[i]])\r\n",
    "                im = cv2.resize(im,(imgDimension,imgDimension))\r\n",
    "                im= augment(im,augType)\r\n",
    "                im= np.einsum('lij->jli', im)\r\n",
    "                xI[i + (x*K)] = im\r\n",
    "                yConcat [i + (x*K)] = y2\r\n",
    "                yConcat [i + (x*K)][-1] = numFm[x]\r\n",
    "\r\n",
    "        xI = np.einsum('abcd->acdb',xI)\r\n",
    "        yield (xI,yConcat)\r\n",
    "        \r\n",
    "'''\r\n",
    "asoftmax loss for keras, takes in the true and predicted logits. \r\n",
    "Feature vector is passed to this loss function, logits calculated outside.\r\n",
    "Works on concatenated logit/feature vector list, taken from https://github.com/pppoe/tensorflow-sphereface-asoftmax on github\r\n",
    "'''\r\n",
    "def Loss_ASoftmax(true, pred):\r\n",
    "    '''\r\n",
    "    x: B x D - data\r\n",
    "    y: B x 1 - label\r\n",
    "    l: 1 - lambda \r\n",
    "    '''\r\n",
    "    m = 4\r\n",
    "    num_cls = CLASSES\r\n",
    "    x = pred[:,CLASSES:]\r\n",
    "    yX = true[:,-1]\r\n",
    "    y = tf.cast(yX, tf.int32)\r\n",
    "    l = 1.0\r\n",
    "    eps = 1e-8\r\n",
    "\r\n",
    "    logits = pred[:,:CLASSES]\r\n",
    "    if m == 0:\r\n",
    "\r\n",
    "        return tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits))\r\n",
    "\r\n",
    "    ordinal = tf.constant(list(range(0, BATCH_SIZE)))\r\n",
    "    ordinal_y = tf.stack([ordinal, y], axis = 1)\r\n",
    "\r\n",
    "    x_norm = tf.norm(x, axis = 1) + eps\r\n",
    "    print(x_norm)\r\n",
    "    sel_logits = tf.gather_nd(logits, ordinal_y)\r\n",
    "\r\n",
    "    cos_th = tf.div(sel_logits, x_norm)\r\n",
    "    if m == 1:\r\n",
    "\r\n",
    "        loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits))\r\n",
    "\r\n",
    "    else:\r\n",
    "\r\n",
    "        if m == 2:\r\n",
    "\r\n",
    "            cos_sign = tf.sign(cos_th)\r\n",
    "            res = 2*tf.multiply(tf.sign(cos_th), tf.square(cos_th)) - 1\r\n",
    "\r\n",
    "        elif m == 4:\r\n",
    "\r\n",
    "            cos_th2 = tf.square(cos_th)\r\n",
    "            cos_th4 = tf.pow(cos_th, 4)\r\n",
    "            sign0 = tf.sign(cos_th)\r\n",
    "            sign3 = tf.multiply(tf.sign(2*cos_th2 - 1), sign0)\r\n",
    "            sign4 = 2*sign0 + sign3 - 3\r\n",
    "            res = sign3*(8*cos_th4 - 8*cos_th2 + 1) + sign4\r\n",
    "        else:\r\n",
    "            raise ValueError('unsupported value of m')\r\n",
    "\r\n",
    "        scaled_logits = tf.multiply(res, x_norm)\r\n",
    "\r\n",
    "        f = 1.0/(1.0+l)\r\n",
    "        ff = 1.0 - f\r\n",
    "        blah = tf.subtract(scaled_logits, sel_logits)\r\n",
    "        print (blah)\r\n",
    "        print (ordinal_y)\r\n",
    "        b = tf.constant([BATCH_SIZE,CLASSES])\r\n",
    "\r\n",
    "        blah1 = tf.scatter_nd(ordinal_y,blah , b)\r\n",
    "        comb_logits_diff = tf.add(logits, blah1) \r\n",
    "        updated_logits = ff*logits + f*comb_logits_diff\r\n",
    "        updated_logits = updated_logits*32\r\n",
    "        loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=updated_logits))\r\n",
    "\r\n",
    "    return loss\r\n",
    "\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "    Batch hard loss implementation from https://omoindrot.github.io/triplet-loss\r\n",
    "    Modified to use a soft margin.\r\n",
    "\"\"\"\r\n",
    "def _get_anchor_positive_triplet_mask(labels):\r\n",
    "    \"\"\"Return a 2D mask where mask[a, p] is True iff a and p are distinct and have same label.\r\n",
    "    Args:\r\n",
    "        labels: tf.int32 `Tensor` with shape [batch_size]\r\n",
    "    Returns:\r\n",
    "        mask: tf.bool `Tensor` with shape [batch_size, batch_size]\r\n",
    "    \"\"\"\r\n",
    "    # Check that i and j are distinct\r\n",
    "    indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\r\n",
    "    indices_not_equal = tf.logical_not(indices_equal)\r\n",
    "\r\n",
    "    # Check if labels[i] == labels[j]\r\n",
    "    # Uses broadcasting where the 1st argument has shape (1, batch_size) and the 2nd (batch_size, 1)\r\n",
    "    labels_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\r\n",
    "\r\n",
    "    # Combine the two masks\r\n",
    "    mask = tf.logical_and(indices_not_equal, labels_equal)\r\n",
    "\r\n",
    "    return mask\r\n",
    "\r\n",
    "\r\n",
    "def _get_anchor_negative_triplet_mask(labels):\r\n",
    "    \"\"\"Return a 2D mask where mask[a, n] is True iff a and n have distinct labels.\r\n",
    "    Args:\r\n",
    "        labels: tf.int32 `Tensor` with shape [batch_size]\r\n",
    "    Returns:\r\n",
    "        mask: tf.bool `Tensor` with shape [batch_size, batch_size]\r\n",
    "    \"\"\"\r\n",
    "    # Check if labels[i] != labels[k]\r\n",
    "    # Uses broadcasting where the 1st argument has shape (1, batch_size) and the 2nd (batch_size, 1)\r\n",
    "    labels_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\r\n",
    "\r\n",
    "    mask = tf.logical_not(labels_equal)\r\n",
    "\r\n",
    "    return mask\r\n",
    "def _get_triplet_mask(labels):\r\n",
    "    \"\"\"Return a 3D mask where mask[a, p, n] is True iff the triplet (a, p, n) is valid.\r\n",
    "    A triplet (i, j, k) is valid if:\r\n",
    "        - i, j, k are distinct\r\n",
    "        - labels[i] == labels[j] and labels[i] != labels[k]\r\n",
    "    Args:\r\n",
    "        labels: tf.int32 `Tensor` with shape [batch_size]\r\n",
    "    \"\"\"\r\n",
    "    # Check that i, j and k are distinct\r\n",
    "    indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\r\n",
    "    indices_not_equal = tf.logical_not(indices_equal)\r\n",
    "    i_not_equal_j = tf.expand_dims(indices_not_equal, 2)\r\n",
    "    i_not_equal_k = tf.expand_dims(indices_not_equal, 1)\r\n",
    "    j_not_equal_k = tf.expand_dims(indices_not_equal, 0)\r\n",
    "\r\n",
    "    distinct_indices = tf.logical_and(tf.logical_and(i_not_equal_j, i_not_equal_k), j_not_equal_k)\r\n",
    "\r\n",
    "\r\n",
    "    # Check if labels[i] == labels[j] and labels[i] != labels[k]\r\n",
    "    label_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\r\n",
    "    i_equal_j = tf.expand_dims(label_equal, 2)\r\n",
    "    i_equal_k = tf.expand_dims(label_equal, 1)\r\n",
    "\r\n",
    "    valid_labels = tf.logical_and(i_equal_j, tf.logical_not(i_equal_k))\r\n",
    "\r\n",
    "    # Combine the two masks\r\n",
    "    mask = tf.logical_and(distinct_indices, valid_labels)\r\n",
    "\r\n",
    "    return mask\r\n",
    "\r\n",
    "def batch_hard_triplet_loss(true, pred, squared=False):\r\n",
    "    \"\"\"Build the triplet loss over a batch of embeddings.\r\n",
    "\r\n",
    "    For each anchor, we get the hardest positive and hardest negative to form a triplet.\r\n",
    "\r\n",
    "    Args:\r\n",
    "        labels: labels of the batch, of size (batch_size,)\r\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\r\n",
    "        margin: margin for triplet loss\r\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\r\n",
    "                 If false, output is the pairwise euclidean distance matrix.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "        triplet_loss: scalar tensor containing the triplet loss\r\n",
    "    \"\"\"\r\n",
    "    \r\n",
    "    embeddings = pred[:,:-1]\r\n",
    "    labels = true[:,-1]\r\n",
    "    margin = 0.8\r\n",
    "    # Get the pairwise distance matrix\r\n",
    "    pairwise_dist = _pairwise_distances(embeddings, squared=squared)\r\n",
    "\r\n",
    "    # For each anchor, get the hardest positive\r\n",
    "    # First, we need to get a mask for every valid positive (they should have same label)\r\n",
    "    mask_anchor_positive = _get_anchor_positive_triplet_mask(labels)\r\n",
    "    mask_anchor_positive = tf.to_float(mask_anchor_positive)\r\n",
    "\r\n",
    "    # We put to 0 any element where (a, p) is not valid (valid if a != p and label(a) == label(p))\r\n",
    "    anchor_positive_dist = tf.multiply(mask_anchor_positive, pairwise_dist)\r\n",
    "\r\n",
    "    # shape (batch_size, 1)\r\n",
    "    hardest_positive_dist = tf.reduce_max(anchor_positive_dist, axis=1, keepdims=True)\r\n",
    "\r\n",
    "    # For each anchor, get the hardest negative\r\n",
    "    # First, we need to get a mask for every valid negative (they should have different labels)\r\n",
    "    mask_anchor_negative = _get_anchor_negative_triplet_mask(labels)\r\n",
    "    mask_anchor_negative = tf.to_float(mask_anchor_negative)\r\n",
    "\r\n",
    "    # We add the maximum value in each row to the invalid negatives (label(a) == label(n))\r\n",
    "    max_anchor_negative_dist = tf.reduce_max(pairwise_dist, axis=1, keepdims=True)\r\n",
    "    anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (1.0 - mask_anchor_negative)\r\n",
    "\r\n",
    "    # shape (batch_size,)\r\n",
    "    hardest_negative_dist = tf.reduce_min(anchor_negative_dist, axis=1, keepdims=True)\r\n",
    "#     hP = K.max(hardest_positive_dist)\r\n",
    "#     hN =  K.min(hardest_negative_dist)\r\n",
    "    # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\r\n",
    "    #Usual batch hard triplet loss:\r\n",
    "#     triplet_loss = tf.maximum(hP - hN + margin, 0.0)\r\n",
    "\r\n",
    "    #Soft-margin triplet loss\r\n",
    "    triplet_loss = K.log(1.0 + K.exp(hardest_positive_dist - hardest_negative_dist))\r\n",
    "    # Get final mean triplet loss\r\n",
    "    triplet_loss = tf.reduce_mean(triplet_loss)\r\n",
    "\r\n",
    "    return triplet_loss\r\n",
    "def batch_all_triplet_loss(true, pred, squared=False):\r\n",
    "    \"\"\"Build the triplet loss over a batch of embeddings.\r\n",
    "\r\n",
    "    We generate all the valid triplets and average the loss over the positive ones.\r\n",
    "\r\n",
    "    Args:\r\n",
    "        labels: labels of the batch, of size (batch_size,)\r\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\r\n",
    "        margin: margin for triplet loss\r\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\r\n",
    "                 If false, output is the pairwise euclidean distance matrix.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "        triplet_loss: scalar tensor containing the triplet loss\r\n",
    "    \"\"\"\r\n",
    "#     print (labels)\r\n",
    "    embeddings = pred[:,:-1]\r\n",
    "    labels = true[:,-1]\r\n",
    "    \r\n",
    "#     print (embeddings)\r\n",
    "    margin = 0.7\r\n",
    "    # Get the pairwise distance matrix\r\n",
    "    pairwise_dist = _pairwise_distances(embeddings, squared=squared)\r\n",
    "\r\n",
    "    anchor_positive_dist = tf.expand_dims(pairwise_dist, 2)\r\n",
    "    anchor_negative_dist = tf.expand_dims(pairwise_dist, 1)\r\n",
    "\r\n",
    "    # Compute a 3D tensor of size (batch_size, batch_size, batch_size)\r\n",
    "    # triplet_loss[i, j, k] will contain the triplet loss of anchor=i, positive=j, negative=k\r\n",
    "    # Uses broadcasting where the 1st argument has shape (batch_size, batch_size, 1)\r\n",
    "    # and the 2nd (batch_size, 1, batch_size)\r\n",
    "    triplet_loss = anchor_positive_dist - anchor_negative_dist + margin\r\n",
    "\r\n",
    "    # Put to zero the invalid triplets\r\n",
    "    # (where label(a) != label(p) or label(n) == label(a) or a == p)\r\n",
    "    mask = _get_triplet_mask(labels)\r\n",
    "    mask = tf.to_float(mask)\r\n",
    "    triplet_loss = tf.multiply(mask, triplet_loss)\r\n",
    "\r\n",
    "    # Remove negative losses (i.e. the easy triplets)\r\n",
    "    triplet_loss = tf.maximum(triplet_loss, 0.0)\r\n",
    "\r\n",
    "    # Count number of positive triplets (where triplet_loss > 0)\r\n",
    "    valid_triplets = tf.to_float(tf.greater(triplet_loss, 1e-16))\r\n",
    "    num_positive_triplets = tf.reduce_sum(valid_triplets)\r\n",
    "    num_valid_triplets = tf.reduce_sum(mask)\r\n",
    "    fraction_positive_triplets = num_positive_triplets / (num_valid_triplets + 1e-16)\r\n",
    "\r\n",
    "    # Get final mean triplet loss over the positive valid triplets\r\n",
    "    triplet_loss = tf.reduce_sum(triplet_loss) / (num_positive_triplets + 1e-16)\r\n",
    "\r\n",
    "    return triplet_loss\r\n",
    "\r\n",
    "def _pairwise_distances(embeddings, squared=False):\r\n",
    "    \"\"\"Compute the 2D matrix of distances between all the embeddings.\r\n",
    "\r\n",
    "    Args:\r\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\r\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\r\n",
    "                 If false, output is the pairwise euclidean distance matrix.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "        pairwise_distances: tensor of shape (batch_size, batch_size)\r\n",
    "    \"\"\"\r\n",
    "    # Get the dot product between all embeddings\r\n",
    "    # shape (batch_size, batch_size)\r\n",
    "    dot_product = tf.matmul(embeddings, tf.transpose(embeddings))\r\n",
    "\r\n",
    "    # Get squared L2 norm for each embedding. We can just take the diagonal of `dot_product`.\r\n",
    "    # This also provides more numerical stability (the diagonal of the result will be exactly 0).\r\n",
    "    # shape (batch_size,)\r\n",
    "    square_norm = tf.diag_part(dot_product)\r\n",
    "\r\n",
    "    # Compute the pairwise distance matrix as we have:\r\n",
    "    # ||a - b||^2 = ||a||^2  - 2 <a, b> + ||b||^2\r\n",
    "    # shape (batch_size, batch_size)\r\n",
    "#     distances = tf.expand_dims(square_norm, 0) - 2.0 * dot_product + tf.expand_dims(square_norm, 1)\r\n",
    "    distances =  (dot_product/tf.expand_dims(square_norm, 0)*tf.expand_dims(square_norm, 1))\r\n",
    "    # Because of computation errors, some distances might be negative so we put everything >= 0.0\r\n",
    "    distances = 1-distances\r\n",
    "    distances = tf.maximum(distances, 0.0)\r\n",
    "\r\n",
    "    if not squared:\r\n",
    "        # Because the gradient of sqrt is infinite when distances == 0.0 (ex: on the diagonal)\r\n",
    "        # we need to add a small epsilon where distances == 0.0\r\n",
    "        mask = tf.to_float(tf.equal(distances, 0.0))\r\n",
    "        distances = distances + mask * 1e-8\r\n",
    "\r\n",
    "        distances = tf.sqrt(distances)\r\n",
    "\r\n",
    "        # Correct the epsilon added: set the distances on the mask to be exactly 0.0\r\n",
    "        distances = distances * (1.0 - mask)\r\n",
    "\r\n",
    "    return distances\r\n",
    "\r\n",
    "def l2Norm(x):\r\n",
    "    return  K.l2_normalize(x, axis=1)\r\n",
    "\r\n",
    "\r\n",
    "#defines the classification model\r\n",
    "def classification_model(base_model):\r\n",
    "    x = base_model.output\r\n",
    "    x = GlobalAveragePooling2D()(x)\r\n",
    "    x = BatchNormalization()(x)\r\n",
    "    x = Dropout(0.1)(x)\r\n",
    "\r\n",
    "    fc2 = Dense(FEATURES,activation = 'relu',name = 'embedding_weights',use_bias = False)(x)\r\n",
    "    fc2 = BatchNormalization()(fc2)\r\n",
    "    out = Lambda(lambda x: K.l2_normalize(x, axis=1))(fc2)\r\n",
    "    label = Dense(1,activation='linear',name = 'label')(out)\r\n",
    "    \r\n",
    "    conc = concatenate([fc2, label], name='xF')\r\n",
    "\r\n",
    "    return conc\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\r\n",
    "\"\"\"Model generation\"\"\"\r\n",
    "inp = Input(shape = (3,imgDimension,imgDimension))\r\n",
    "base_model = densenet.DenseNet169(weights='imagenet', include_top=False,input_shape=(3,imgDimension,imgDimension))\r\n",
    "\r\n",
    "\r\n",
    "print (\"Loaded initial model\")\r\n",
    "\r\n",
    "triplet_model = Model(inputs=base_model.input, outputs=classification_model(base_model))\r\n",
    "\r\n",
    "\"\"\"Model generation\"\"\"\r\n",
    "\r\n",
    "cwd = os.getcwd()\r\n",
    "filepath=cwd + \"/batchHard_ResNet50-{epoch:02d}-{loss:.2f}.hdf5\"\r\n",
    "\r\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\r\n",
    "\r\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_predictions_acc', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\r\n",
    "callbacks_list = [checkpoint]\r\n",
    "print (triplet_model.summary())\r\n",
    "\r\n",
    "# triplet_model.load_weights(\"/home/sohaib/Downloads/Features/batchHard_ResNet50-08-0.58.hdf5\",by_name = True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From E:\\Dev\\Anaconda3\\envs\\iris\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\Dev\\Anaconda3\\envs\\iris\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "Loaded initial model\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 3, 256, 256)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 3, 262, 262)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 64, 128, 128) 9408        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 64, 128, 128) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 64, 128, 128) 0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 64, 130, 130) 0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 64, 64, 64)   0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 64, 64, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 64, 64, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 128, 64, 64)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 128, 64, 64)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 128, 64, 64)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 32, 64, 64)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 96, 64, 64)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 96, 64, 64)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 96, 64, 64)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 128, 64, 64)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 128, 64, 64)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 128, 64, 64)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 32, 64, 64)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 128, 64, 64)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 128, 64, 64)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 128, 64, 64)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 128, 64, 64)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 128, 64, 64)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 128, 64, 64)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 32, 64, 64)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 160, 64, 64)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 160, 64, 64)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 160, 64, 64)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 128, 64, 64)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 128, 64, 64)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 128, 64, 64)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 32, 64, 64)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 192, 64, 64)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 192, 64, 64)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 192, 64, 64)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 128, 64, 64)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 128, 64, 64)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 128, 64, 64)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 32, 64, 64)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 224, 64, 64)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 224, 64, 64)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 224, 64, 64)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 128, 64, 64)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 128, 64, 64)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 128, 64, 64)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 32, 64, 64)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 256, 64, 64)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 256, 64, 64)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 256, 64, 64)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 128, 64, 64)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 128, 32, 32)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 128, 32, 32)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 128, 32, 32)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 128, 32, 32)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 128, 32, 32)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 128, 32, 32)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 160, 32, 32)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 160, 32, 32)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 160, 32, 32)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 128, 32, 32)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 128, 32, 32)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 128, 32, 32)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 192, 32, 32)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 192, 32, 32)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 192, 32, 32)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 128, 32, 32)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 128, 32, 32)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 128, 32, 32)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 224, 32, 32)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 224, 32, 32)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 224, 32, 32)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 128, 32, 32)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 128, 32, 32)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 128, 32, 32)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 256, 32, 32)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 256, 32, 32)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 256, 32, 32)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 128, 32, 32)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 128, 32, 32)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 128, 32, 32)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 288, 32, 32)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 288, 32, 32)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 288, 32, 32)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 128, 32, 32)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 128, 32, 32)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 128, 32, 32)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 320, 32, 32)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 320, 32, 32)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 320, 32, 32)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 128, 32, 32)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 128, 32, 32)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 128, 32, 32)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 352, 32, 32)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 352, 32, 32)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 352, 32, 32)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 128, 32, 32)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 128, 32, 32)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 128, 32, 32)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 384, 32, 32)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 384, 32, 32)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 384, 32, 32)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 128, 32, 32)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 128, 32, 32)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 128, 32, 32)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 416, 32, 32)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 416, 32, 32)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 416, 32, 32)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 128, 32, 32)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 128, 32, 32)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 128, 32, 32)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 448, 32, 32)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 448, 32, 32)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 448, 32, 32)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 128, 32, 32)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 128, 32, 32)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 128, 32, 32)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 480, 32, 32)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 480, 32, 32)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 480, 32, 32)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 128, 32, 32)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 128, 32, 32)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 128, 32, 32)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 512, 32, 32)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 512, 32, 32)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 512, 32, 32)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 256, 32, 32)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 256, 16, 16)  0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 256, 16, 16)  1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 256, 16, 16)  0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 128, 16, 16)  32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 128, 16, 16)  512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 128, 16, 16)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 32, 16, 16)   36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 288, 16, 16)  0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 288, 16, 16)  1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 288, 16, 16)  0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 128, 16, 16)  36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 128, 16, 16)  512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 128, 16, 16)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 32, 16, 16)   36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 320, 16, 16)  0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 320, 16, 16)  1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 320, 16, 16)  0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 128, 16, 16)  40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 128, 16, 16)  512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 128, 16, 16)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 32, 16, 16)   36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 352, 16, 16)  0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 352, 16, 16)  1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 352, 16, 16)  0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 128, 16, 16)  45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 128, 16, 16)  512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 128, 16, 16)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 32, 16, 16)   36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 384, 16, 16)  0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 384, 16, 16)  1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 384, 16, 16)  0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 128, 16, 16)  49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 128, 16, 16)  512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 128, 16, 16)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 32, 16, 16)   36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 416, 16, 16)  0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 416, 16, 16)  1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 416, 16, 16)  0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 128, 16, 16)  53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 128, 16, 16)  512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 128, 16, 16)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 32, 16, 16)   36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 448, 16, 16)  0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 448, 16, 16)  1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 448, 16, 16)  0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 128, 16, 16)  57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 128, 16, 16)  512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 128, 16, 16)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 32, 16, 16)   36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 480, 16, 16)  0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 480, 16, 16)  1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 480, 16, 16)  0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 128, 16, 16)  61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 128, 16, 16)  512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 128, 16, 16)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 32, 16, 16)   36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 512, 16, 16)  0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 512, 16, 16)  2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 512, 16, 16)  0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 128, 16, 16)  65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 128, 16, 16)  512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 128, 16, 16)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 32, 16, 16)   36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 544, 16, 16)  0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 544, 16, 16)  2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 544, 16, 16)  0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 128, 16, 16)  69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 128, 16, 16)  512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 128, 16, 16)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 32, 16, 16)   36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 576, 16, 16)  0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 576, 16, 16)  2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 576, 16, 16)  0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 128, 16, 16)  73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 128, 16, 16)  512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 128, 16, 16)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 32, 16, 16)   36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 608, 16, 16)  0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 608, 16, 16)  2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 608, 16, 16)  0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 128, 16, 16)  77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 128, 16, 16)  512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 128, 16, 16)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 32, 16, 16)   36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 640, 16, 16)  0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 640, 16, 16)  2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 640, 16, 16)  0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 128, 16, 16)  81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 128, 16, 16)  512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 128, 16, 16)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 32, 16, 16)   36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 672, 16, 16)  0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 672, 16, 16)  2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 672, 16, 16)  0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 128, 16, 16)  86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 128, 16, 16)  512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 128, 16, 16)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 32, 16, 16)   36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 704, 16, 16)  0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 704, 16, 16)  2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 704, 16, 16)  0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 128, 16, 16)  90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 128, 16, 16)  512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 128, 16, 16)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 32, 16, 16)   36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 736, 16, 16)  0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 736, 16, 16)  2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 736, 16, 16)  0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 128, 16, 16)  94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 128, 16, 16)  512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 128, 16, 16)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 32, 16, 16)   36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 768, 16, 16)  0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 768, 16, 16)  3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 768, 16, 16)  0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 128, 16, 16)  98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 128, 16, 16)  512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 128, 16, 16)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 32, 16, 16)   36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 800, 16, 16)  0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 800, 16, 16)  3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 800, 16, 16)  0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 128, 16, 16)  102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 128, 16, 16)  512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 128, 16, 16)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 32, 16, 16)   36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 832, 16, 16)  0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 832, 16, 16)  3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 832, 16, 16)  0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 128, 16, 16)  106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 128, 16, 16)  512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 128, 16, 16)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 32, 16, 16)   36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 864, 16, 16)  0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 864, 16, 16)  3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 864, 16, 16)  0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 128, 16, 16)  110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 128, 16, 16)  512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 128, 16, 16)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 32, 16, 16)   36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 896, 16, 16)  0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 896, 16, 16)  3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 896, 16, 16)  0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 128, 16, 16)  114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 128, 16, 16)  512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 128, 16, 16)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 32, 16, 16)   36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 928, 16, 16)  0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 928, 16, 16)  3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 928, 16, 16)  0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 128, 16, 16)  118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 128, 16, 16)  512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 128, 16, 16)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 32, 16, 16)   36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 960, 16, 16)  0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 960, 16, 16)  3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 960, 16, 16)  0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 128, 16, 16)  122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 128, 16, 16)  512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 128, 16, 16)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 32, 16, 16)   36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 992, 16, 16)  0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 992, 16, 16)  3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 992, 16, 16)  0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 128, 16, 16)  126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 128, 16, 16)  512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 128, 16, 16)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 32, 16, 16)   36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 1024, 16, 16) 0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_0_bn (BatchNormal (None, 1024, 16, 16) 4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_0_relu (Activatio (None, 1024, 16, 16) 0           conv4_block25_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_conv (Conv2D)   (None, 128, 16, 16)  131072      conv4_block25_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_bn (BatchNormal (None, 128, 16, 16)  512         conv4_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_relu (Activatio (None, 128, 16, 16)  0           conv4_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_conv (Conv2D)   (None, 32, 16, 16)   36864       conv4_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_concat (Concatena (None, 1056, 16, 16) 0           conv4_block24_concat[0][0]       \n",
      "                                                                 conv4_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_0_bn (BatchNormal (None, 1056, 16, 16) 4224        conv4_block25_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_0_relu (Activatio (None, 1056, 16, 16) 0           conv4_block26_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_conv (Conv2D)   (None, 128, 16, 16)  135168      conv4_block26_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_bn (BatchNormal (None, 128, 16, 16)  512         conv4_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_relu (Activatio (None, 128, 16, 16)  0           conv4_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_conv (Conv2D)   (None, 32, 16, 16)   36864       conv4_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_concat (Concatena (None, 1088, 16, 16) 0           conv4_block25_concat[0][0]       \n",
      "                                                                 conv4_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_0_bn (BatchNormal (None, 1088, 16, 16) 4352        conv4_block26_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_0_relu (Activatio (None, 1088, 16, 16) 0           conv4_block27_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_conv (Conv2D)   (None, 128, 16, 16)  139264      conv4_block27_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_bn (BatchNormal (None, 128, 16, 16)  512         conv4_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_relu (Activatio (None, 128, 16, 16)  0           conv4_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_conv (Conv2D)   (None, 32, 16, 16)   36864       conv4_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_concat (Concatena (None, 1120, 16, 16) 0           conv4_block26_concat[0][0]       \n",
      "                                                                 conv4_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_0_bn (BatchNormal (None, 1120, 16, 16) 4480        conv4_block27_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_0_relu (Activatio (None, 1120, 16, 16) 0           conv4_block28_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_conv (Conv2D)   (None, 128, 16, 16)  143360      conv4_block28_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_bn (BatchNormal (None, 128, 16, 16)  512         conv4_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_relu (Activatio (None, 128, 16, 16)  0           conv4_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_conv (Conv2D)   (None, 32, 16, 16)   36864       conv4_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_concat (Concatena (None, 1152, 16, 16) 0           conv4_block27_concat[0][0]       \n",
      "                                                                 conv4_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_0_bn (BatchNormal (None, 1152, 16, 16) 4608        conv4_block28_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_0_relu (Activatio (None, 1152, 16, 16) 0           conv4_block29_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_conv (Conv2D)   (None, 128, 16, 16)  147456      conv4_block29_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_bn (BatchNormal (None, 128, 16, 16)  512         conv4_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_relu (Activatio (None, 128, 16, 16)  0           conv4_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_conv (Conv2D)   (None, 32, 16, 16)   36864       conv4_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_concat (Concatena (None, 1184, 16, 16) 0           conv4_block28_concat[0][0]       \n",
      "                                                                 conv4_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_0_bn (BatchNormal (None, 1184, 16, 16) 4736        conv4_block29_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_0_relu (Activatio (None, 1184, 16, 16) 0           conv4_block30_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_conv (Conv2D)   (None, 128, 16, 16)  151552      conv4_block30_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_bn (BatchNormal (None, 128, 16, 16)  512         conv4_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_relu (Activatio (None, 128, 16, 16)  0           conv4_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_conv (Conv2D)   (None, 32, 16, 16)   36864       conv4_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_concat (Concatena (None, 1216, 16, 16) 0           conv4_block29_concat[0][0]       \n",
      "                                                                 conv4_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_0_bn (BatchNormal (None, 1216, 16, 16) 4864        conv4_block30_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_0_relu (Activatio (None, 1216, 16, 16) 0           conv4_block31_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_conv (Conv2D)   (None, 128, 16, 16)  155648      conv4_block31_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_bn (BatchNormal (None, 128, 16, 16)  512         conv4_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_relu (Activatio (None, 128, 16, 16)  0           conv4_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_conv (Conv2D)   (None, 32, 16, 16)   36864       conv4_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_concat (Concatena (None, 1248, 16, 16) 0           conv4_block30_concat[0][0]       \n",
      "                                                                 conv4_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_0_bn (BatchNormal (None, 1248, 16, 16) 4992        conv4_block31_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_0_relu (Activatio (None, 1248, 16, 16) 0           conv4_block32_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_conv (Conv2D)   (None, 128, 16, 16)  159744      conv4_block32_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_bn (BatchNormal (None, 128, 16, 16)  512         conv4_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_relu (Activatio (None, 128, 16, 16)  0           conv4_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_conv (Conv2D)   (None, 32, 16, 16)   36864       conv4_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_concat (Concatena (None, 1280, 16, 16) 0           conv4_block31_concat[0][0]       \n",
      "                                                                 conv4_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 1280, 16, 16) 5120        conv4_block32_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 1280, 16, 16) 0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 640, 16, 16)  819200      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 640, 8, 8)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 640, 8, 8)    2560        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 640, 8, 8)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 128, 8, 8)    81920       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 128, 8, 8)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 128, 8, 8)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 32, 8, 8)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 672, 8, 8)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 672, 8, 8)    2688        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 672, 8, 8)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 128, 8, 8)    86016       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 128, 8, 8)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 128, 8, 8)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 32, 8, 8)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 704, 8, 8)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 704, 8, 8)    2816        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 704, 8, 8)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 128, 8, 8)    90112       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 128, 8, 8)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 128, 8, 8)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 32, 8, 8)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 736, 8, 8)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 736, 8, 8)    2944        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 736, 8, 8)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 128, 8, 8)    94208       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 128, 8, 8)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 128, 8, 8)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 32, 8, 8)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 768, 8, 8)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 768, 8, 8)    3072        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 768, 8, 8)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 128, 8, 8)    98304       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 128, 8, 8)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 128, 8, 8)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 32, 8, 8)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 800, 8, 8)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 800, 8, 8)    3200        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 800, 8, 8)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 128, 8, 8)    102400      conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 128, 8, 8)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 128, 8, 8)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 32, 8, 8)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 832, 8, 8)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 832, 8, 8)    3328        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 832, 8, 8)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 128, 8, 8)    106496      conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 128, 8, 8)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 128, 8, 8)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 32, 8, 8)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 864, 8, 8)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 864, 8, 8)    3456        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 864, 8, 8)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 128, 8, 8)    110592      conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 128, 8, 8)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 128, 8, 8)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 32, 8, 8)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 896, 8, 8)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 896, 8, 8)    3584        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 896, 8, 8)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 128, 8, 8)    114688      conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 128, 8, 8)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 128, 8, 8)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 32, 8, 8)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 928, 8, 8)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 928, 8, 8)    3712        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 928, 8, 8)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 128, 8, 8)    118784      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 128, 8, 8)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 128, 8, 8)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 32, 8, 8)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 960, 8, 8)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 960, 8, 8)    3840        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 960, 8, 8)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 128, 8, 8)    122880      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 128, 8, 8)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 128, 8, 8)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 32, 8, 8)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 992, 8, 8)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 992, 8, 8)    3968        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 992, 8, 8)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 128, 8, 8)    126976      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 128, 8, 8)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 128, 8, 8)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 32, 8, 8)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 1024, 8, 8)   0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 1024, 8, 8)   4096        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 1024, 8, 8)   0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 128, 8, 8)    131072      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 128, 8, 8)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 128, 8, 8)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 32, 8, 8)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 1056, 8, 8)   0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 1056, 8, 8)   4224        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 1056, 8, 8)   0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 128, 8, 8)    135168      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 128, 8, 8)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 128, 8, 8)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 32, 8, 8)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 1088, 8, 8)   0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 1088, 8, 8)   4352        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 1088, 8, 8)   0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 128, 8, 8)    139264      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 128, 8, 8)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 128, 8, 8)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 32, 8, 8)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 1120, 8, 8)   0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 1120, 8, 8)   4480        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 1120, 8, 8)   0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 128, 8, 8)    143360      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 128, 8, 8)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 128, 8, 8)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 32, 8, 8)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 1152, 8, 8)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_0_bn (BatchNormal (None, 1152, 8, 8)   4608        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_0_relu (Activatio (None, 1152, 8, 8)   0           conv5_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_conv (Conv2D)   (None, 128, 8, 8)    147456      conv5_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_bn (BatchNormal (None, 128, 8, 8)    512         conv5_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_relu (Activatio (None, 128, 8, 8)    0           conv5_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_2_conv (Conv2D)   (None, 32, 8, 8)     36864       conv5_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_concat (Concatena (None, 1184, 8, 8)   0           conv5_block16_concat[0][0]       \n",
      "                                                                 conv5_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_0_bn (BatchNormal (None, 1184, 8, 8)   4736        conv5_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_0_relu (Activatio (None, 1184, 8, 8)   0           conv5_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_conv (Conv2D)   (None, 128, 8, 8)    151552      conv5_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_bn (BatchNormal (None, 128, 8, 8)    512         conv5_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_relu (Activatio (None, 128, 8, 8)    0           conv5_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_2_conv (Conv2D)   (None, 32, 8, 8)     36864       conv5_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_concat (Concatena (None, 1216, 8, 8)   0           conv5_block17_concat[0][0]       \n",
      "                                                                 conv5_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_0_bn (BatchNormal (None, 1216, 8, 8)   4864        conv5_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_0_relu (Activatio (None, 1216, 8, 8)   0           conv5_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_conv (Conv2D)   (None, 128, 8, 8)    155648      conv5_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_bn (BatchNormal (None, 128, 8, 8)    512         conv5_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_relu (Activatio (None, 128, 8, 8)    0           conv5_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_2_conv (Conv2D)   (None, 32, 8, 8)     36864       conv5_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_concat (Concatena (None, 1248, 8, 8)   0           conv5_block18_concat[0][0]       \n",
      "                                                                 conv5_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_0_bn (BatchNormal (None, 1248, 8, 8)   4992        conv5_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_0_relu (Activatio (None, 1248, 8, 8)   0           conv5_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_conv (Conv2D)   (None, 128, 8, 8)    159744      conv5_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_bn (BatchNormal (None, 128, 8, 8)    512         conv5_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_relu (Activatio (None, 128, 8, 8)    0           conv5_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_2_conv (Conv2D)   (None, 32, 8, 8)     36864       conv5_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_concat (Concatena (None, 1280, 8, 8)   0           conv5_block19_concat[0][0]       \n",
      "                                                                 conv5_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_0_bn (BatchNormal (None, 1280, 8, 8)   5120        conv5_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_0_relu (Activatio (None, 1280, 8, 8)   0           conv5_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_conv (Conv2D)   (None, 128, 8, 8)    163840      conv5_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_bn (BatchNormal (None, 128, 8, 8)    512         conv5_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_relu (Activatio (None, 128, 8, 8)    0           conv5_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_2_conv (Conv2D)   (None, 32, 8, 8)     36864       conv5_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_concat (Concatena (None, 1312, 8, 8)   0           conv5_block20_concat[0][0]       \n",
      "                                                                 conv5_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_0_bn (BatchNormal (None, 1312, 8, 8)   5248        conv5_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_0_relu (Activatio (None, 1312, 8, 8)   0           conv5_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_conv (Conv2D)   (None, 128, 8, 8)    167936      conv5_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_bn (BatchNormal (None, 128, 8, 8)    512         conv5_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_relu (Activatio (None, 128, 8, 8)    0           conv5_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_2_conv (Conv2D)   (None, 32, 8, 8)     36864       conv5_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_concat (Concatena (None, 1344, 8, 8)   0           conv5_block21_concat[0][0]       \n",
      "                                                                 conv5_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_0_bn (BatchNormal (None, 1344, 8, 8)   5376        conv5_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_0_relu (Activatio (None, 1344, 8, 8)   0           conv5_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_conv (Conv2D)   (None, 128, 8, 8)    172032      conv5_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_bn (BatchNormal (None, 128, 8, 8)    512         conv5_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_relu (Activatio (None, 128, 8, 8)    0           conv5_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_2_conv (Conv2D)   (None, 32, 8, 8)     36864       conv5_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_concat (Concatena (None, 1376, 8, 8)   0           conv5_block22_concat[0][0]       \n",
      "                                                                 conv5_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_0_bn (BatchNormal (None, 1376, 8, 8)   5504        conv5_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_0_relu (Activatio (None, 1376, 8, 8)   0           conv5_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_conv (Conv2D)   (None, 128, 8, 8)    176128      conv5_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_bn (BatchNormal (None, 128, 8, 8)    512         conv5_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_relu (Activatio (None, 128, 8, 8)    0           conv5_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_2_conv (Conv2D)   (None, 32, 8, 8)     36864       conv5_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_concat (Concatena (None, 1408, 8, 8)   0           conv5_block23_concat[0][0]       \n",
      "                                                                 conv5_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_0_bn (BatchNormal (None, 1408, 8, 8)   5632        conv5_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_0_relu (Activatio (None, 1408, 8, 8)   0           conv5_block25_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_conv (Conv2D)   (None, 128, 8, 8)    180224      conv5_block25_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_bn (BatchNormal (None, 128, 8, 8)    512         conv5_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_relu (Activatio (None, 128, 8, 8)    0           conv5_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_2_conv (Conv2D)   (None, 32, 8, 8)     36864       conv5_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_concat (Concatena (None, 1440, 8, 8)   0           conv5_block24_concat[0][0]       \n",
      "                                                                 conv5_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_0_bn (BatchNormal (None, 1440, 8, 8)   5760        conv5_block25_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_0_relu (Activatio (None, 1440, 8, 8)   0           conv5_block26_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_conv (Conv2D)   (None, 128, 8, 8)    184320      conv5_block26_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_bn (BatchNormal (None, 128, 8, 8)    512         conv5_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_relu (Activatio (None, 128, 8, 8)    0           conv5_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_2_conv (Conv2D)   (None, 32, 8, 8)     36864       conv5_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_concat (Concatena (None, 1472, 8, 8)   0           conv5_block25_concat[0][0]       \n",
      "                                                                 conv5_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_0_bn (BatchNormal (None, 1472, 8, 8)   5888        conv5_block26_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_0_relu (Activatio (None, 1472, 8, 8)   0           conv5_block27_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_conv (Conv2D)   (None, 128, 8, 8)    188416      conv5_block27_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_bn (BatchNormal (None, 128, 8, 8)    512         conv5_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_relu (Activatio (None, 128, 8, 8)    0           conv5_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_2_conv (Conv2D)   (None, 32, 8, 8)     36864       conv5_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_concat (Concatena (None, 1504, 8, 8)   0           conv5_block26_concat[0][0]       \n",
      "                                                                 conv5_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_0_bn (BatchNormal (None, 1504, 8, 8)   6016        conv5_block27_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_0_relu (Activatio (None, 1504, 8, 8)   0           conv5_block28_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_conv (Conv2D)   (None, 128, 8, 8)    192512      conv5_block28_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_bn (BatchNormal (None, 128, 8, 8)    512         conv5_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_relu (Activatio (None, 128, 8, 8)    0           conv5_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_2_conv (Conv2D)   (None, 32, 8, 8)     36864       conv5_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_concat (Concatena (None, 1536, 8, 8)   0           conv5_block27_concat[0][0]       \n",
      "                                                                 conv5_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_0_bn (BatchNormal (None, 1536, 8, 8)   6144        conv5_block28_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_0_relu (Activatio (None, 1536, 8, 8)   0           conv5_block29_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_conv (Conv2D)   (None, 128, 8, 8)    196608      conv5_block29_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_bn (BatchNormal (None, 128, 8, 8)    512         conv5_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_relu (Activatio (None, 128, 8, 8)    0           conv5_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_2_conv (Conv2D)   (None, 32, 8, 8)     36864       conv5_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_concat (Concatena (None, 1568, 8, 8)   0           conv5_block28_concat[0][0]       \n",
      "                                                                 conv5_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_0_bn (BatchNormal (None, 1568, 8, 8)   6272        conv5_block29_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_0_relu (Activatio (None, 1568, 8, 8)   0           conv5_block30_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_conv (Conv2D)   (None, 128, 8, 8)    200704      conv5_block30_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_bn (BatchNormal (None, 128, 8, 8)    512         conv5_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_relu (Activatio (None, 128, 8, 8)    0           conv5_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_2_conv (Conv2D)   (None, 32, 8, 8)     36864       conv5_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_concat (Concatena (None, 1600, 8, 8)   0           conv5_block29_concat[0][0]       \n",
      "                                                                 conv5_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_0_bn (BatchNormal (None, 1600, 8, 8)   6400        conv5_block30_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_0_relu (Activatio (None, 1600, 8, 8)   0           conv5_block31_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_conv (Conv2D)   (None, 128, 8, 8)    204800      conv5_block31_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_bn (BatchNormal (None, 128, 8, 8)    512         conv5_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_relu (Activatio (None, 128, 8, 8)    0           conv5_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_2_conv (Conv2D)   (None, 32, 8, 8)     36864       conv5_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_concat (Concatena (None, 1632, 8, 8)   0           conv5_block30_concat[0][0]       \n",
      "                                                                 conv5_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_0_bn (BatchNormal (None, 1632, 8, 8)   6528        conv5_block31_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_0_relu (Activatio (None, 1632, 8, 8)   0           conv5_block32_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_conv (Conv2D)   (None, 128, 8, 8)    208896      conv5_block32_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_bn (BatchNormal (None, 128, 8, 8)    512         conv5_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_relu (Activatio (None, 128, 8, 8)    0           conv5_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_2_conv (Conv2D)   (None, 32, 8, 8)     36864       conv5_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_concat (Concatena (None, 1664, 8, 8)   0           conv5_block31_concat[0][0]       \n",
      "                                                                 conv5_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 1664, 8, 8)   6656        conv5_block32_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 1664, 8, 8)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1664)         0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1664)         6656        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1664)         0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_weights (Dense)       (None, 1024)         1703936     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1024)         4096        embedding_weights[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1024)         0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "label (Dense)                   (None, 1)            1025        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "xF (Concatenate)                (None, 1025)         0           batch_normalization_2[0][0]      \n",
      "                                                                 label[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 14,358,593\n",
      "Trainable params: 14,194,817\n",
      "Non-trainable params: 163,776\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\"\"\"\r\n",
    "    Training happens here, same training and validation generators due to laziness\r\n",
    "\"\"\"\r\n",
    "gen_tr = customGenerator()\r\n",
    "gen_te = customGenerator()\r\n",
    "triplet_model.compile(loss=batch_hard_triplet_loss, optimizer=SGD(0.0009))\r\n",
    "triplet_model.fit_generator(\r\n",
    "    gen_tr,\r\n",
    "    validation_data=gen_te,  \r\n",
    "    epochs=7, \r\n",
    "    verbose=1,\r\n",
    "    workers=4,\r\n",
    "    steps_per_epoch=300, \r\n",
    "    validation_steps=50,\r\n",
    "    use_multiprocessing = True,\r\n",
    "    callbacks = callbacks_list\r\n",
    ")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-1b6105ce6227>:429: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From E:\\Dev\\Anaconda3\\envs\\iris\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From E:\\Dev\\Anaconda3\\envs\\iris\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/7\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "E:\\Dev\\Anaconda3\\envs\\iris\\lib\\site-packages\\keras\\engine\\training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n",
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Dev\\Anaconda3\\envs\\iris\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"E:\\Dev\\Anaconda3\\envs\\iris\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"E:\\Dev\\Anaconda3\\envs\\iris\\lib\\site-packages\\keras\\utils\\data_utils.py\", line 690, in _run\n",
      "    with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:\n",
      "  File \"E:\\Dev\\Anaconda3\\envs\\iris\\lib\\site-packages\\keras\\utils\\data_utils.py\", line 685, in <lambda>\n",
      "    initargs=(seqs, self.random_seed))\n",
      "  File \"E:\\Dev\\Anaconda3\\envs\\iris\\lib\\multiprocessing\\context.py\", line 119, in Pool\n",
      "    context=self.get_context())\n",
      "  File \"E:\\Dev\\Anaconda3\\envs\\iris\\lib\\multiprocessing\\pool.py\", line 174, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"E:\\Dev\\Anaconda3\\envs\\iris\\lib\\multiprocessing\\pool.py\", line 239, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"E:\\Dev\\Anaconda3\\envs\\iris\\lib\\multiprocessing\\process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"E:\\Dev\\Anaconda3\\envs\\iris\\lib\\multiprocessing\\context.py\", line 322, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"E:\\Dev\\Anaconda3\\envs\\iris\\lib\\multiprocessing\\popen_spawn_win32.py\", line 65, in __init__\n",
      "    reduction.dump(process_obj, to_child)\n",
      "  File \"E:\\Dev\\Anaconda3\\envs\\iris\\lib\\multiprocessing\\reduction.py\", line 60, in dump\n",
      "    ForkingPickler(file, protocol).dump(obj)\n",
      "TypeError: can't pickle generator objects\n",
      "\n",
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Dev\\Anaconda3\\envs\\iris\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"E:\\Dev\\Anaconda3\\envs\\iris\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"E:\\Dev\\Anaconda3\\envs\\iris\\lib\\site-packages\\keras\\utils\\data_utils.py\", line 690, in _run\n",
      "    with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:\n",
      "  File \"E:\\Dev\\Anaconda3\\envs\\iris\\lib\\site-packages\\keras\\utils\\data_utils.py\", line 685, in <lambda>\n",
      "    initargs=(seqs, self.random_seed))\n",
      "  File \"E:\\Dev\\Anaconda3\\envs\\iris\\lib\\multiprocessing\\context.py\", line 119, in Pool\n",
      "    context=self.get_context())\n",
      "  File \"E:\\Dev\\Anaconda3\\envs\\iris\\lib\\multiprocessing\\pool.py\", line 174, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"E:\\Dev\\Anaconda3\\envs\\iris\\lib\\multiprocessing\\pool.py\", line 239, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"E:\\Dev\\Anaconda3\\envs\\iris\\lib\\multiprocessing\\process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"E:\\Dev\\Anaconda3\\envs\\iris\\lib\\multiprocessing\\context.py\", line 322, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"E:\\Dev\\Anaconda3\\envs\\iris\\lib\\multiprocessing\\popen_spawn_win32.py\", line 65, in __init__\n",
      "    reduction.dump(process_obj, to_child)\n",
      "  File \"E:\\Dev\\Anaconda3\\envs\\iris\\lib\\multiprocessing\\reduction.py\", line 60, in dump\n",
      "    ForkingPickler(file, protocol).dump(obj)\n",
      "TypeError: can't pickle generator objects\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "    Folder to infer stuff on\r\n",
    "\"\"\"\r\n",
    "ROOT_DIR = os.getcwd()\r\n",
    "imList = sorted(glob.glob(ROOT_DIR+ \"/Folder_to_infer_on/*\"),key=numericalSort)\r\n",
    "print (imList[0])\r\n",
    "print (len(imList))\r\n",
    "\r\n",
    "\r\n",
    "p = 8#multiprocessing cpu_count\r\n",
    "pool = Pool(processes=8)\r\n",
    "print (\"Processors Available = \" + str(p))\r\n",
    "\r\n",
    "\r\n",
    "lst = helperFunc.prepareFeatures(triplet_model,imList,imgDimension,FEATURES)\r\n",
    "lst = np.asarray(lst)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "activations = lst\r\n",
    "\r\n",
    "\r\n",
    "# \"\"\" \r\n",
    "#     Hardcoded stuff for multi core :p\r\n",
    "# \"\"\"\r\n",
    "lst = pool.map(helperFunc.featureSelect,((activations,imList,1),(activations,imList,2),\r\n",
    "                              (activations,imList,3),(activations,imList,4),(activations,imList,5),\r\n",
    "                              (activations,imList,6),(activations,imList,7),(activations,imList,8)))\r\n",
    "\r\n",
    "tP = 0\r\n",
    "masterBlue = []\r\n",
    "masterRed = []\r\n",
    "masterVar = np.zeros(shape = (FEATURES*3))\r\n",
    "for x in range(len(lst)):\r\n",
    "    for y in range(len(lst[x][0])):\r\n",
    "        masterBlue.append(lst[x][0][y])\r\n",
    "    for z in range(len(lst[x][1])):\r\n",
    "        masterRed.append(lst[x][1][z])\r\n",
    "for x in range(len(lst)):\r\n",
    "        tP+= lst[x][2]\r\n",
    "print (\"Total true positives = \" + str(tP))\r\n",
    "masterRed = np.sort(masterRed)\r\n",
    "plt.hist(masterBlue, normed=True, bins=120, histtype='stepfilled', color='b',alpha=0.7, label='Same')\r\n",
    "plt.hist(masterRed, normed=True, bins=120, histtype='stepfilled', color='r', label='Different')\r\n",
    "plt.show()\r\n",
    "\r\n",
    "print (\"Standard deviation same = \" + str(np.std(masterBlue)))\r\n",
    "print (\"Standard deviation different = \" + str(np.std(masterRed)))\r\n",
    "print (\"Blah = \" + str(len(masterBlue)))\r\n",
    "print (\"Min Same class = \" + str(min(masterBlue)))\r\n",
    "print (\"Min Different class = \" + str(min(masterRed)))\r\n",
    "print (\"Minimum = \" + str(masterRed[:60]))\r\n",
    "print (\"Max = \" + str(masterRed[-60:]))\r\n",
    "\r\n",
    "print (\"Average Same class = \" + str(sum(masterBlue) / float(len(masterBlue))))\r\n",
    "print (\"Average Different class = \" + str(sum(masterRed) / float(len(masterRed))))\r\n",
    "\r\n",
    "\r\n",
    "# u = np.mean(masterRed)\r\n",
    "# entropy = (u*(1-u))/np.var(masterRed)\r\n",
    "# print (\"Entropy = \" + str(entropy))\r\n",
    "\r\n",
    "blueFile = open('blue.txt', 'w')\r\n",
    "for item in masterBlue:\r\n",
    "    blueFile.write(\"%s\\n\" % item)\r\n",
    "\r\n",
    "redFile = open('red.txt', 'w')\r\n",
    "for item in masterRed:\r\n",
    "    redFile.write(\"%s\\n\" % item)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('iris': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "interpreter": {
   "hash": "3d61305c59383f0c6055cbc182c4f9a517046ab684024aadafcd882b54b1f1b3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}